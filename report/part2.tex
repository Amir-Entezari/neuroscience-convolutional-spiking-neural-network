\chapter{روش های ارتباطی بین لایه های مختلف در شبکه های عصبی ضربه‌ای}
    \section{مقدمه}
    در این بخش از پروژه، هدف ما ساخت و پیاده‌سازی یک شبکه عصبی ضربه‌ای است که بتواند ویژگی های تکراری از تصاویر ورودی را پردازش، تحلیل و پیدا کند.شبکه‌های عصبی ضربه‌ای 
    (SNN) 
    نوعی از شبکه‌های عصبی مصنوعی هستند که الهام گرفته از شبکه‌های عصبی بیولوژیکی و نحوه عملکرد نورون‌های مغز می‌باشند. برخلاف شبکه‌های عصبی سنتی، نورون‌ها در 
    SNN 
    به جای تولید سیگنال‌های پیوسته، سیگنال‌های گسسته و ضربه‌ای تولید می‌کنند که به آن‌ها امکان می‌دهد تا اطلاعات را به شیوه‌ای کارآمدتر و با مصرف انرژی کمتر پردازش کنند.

    در این پروژه، شبکه عصبی ضربه‌ای ما از فیلترهای 
    DoG (\lr{Difference of Gaussian}) 
    برای کدگذاری اولیه تصاویر استفاده می‌کند. فیلترهای 
    DoG 
    به دلیل توانایی بالا در استخراج ویژگی‌های مهم از تصاویر، به عنوان ابزارهای اصلی در مراحل پیش‌پردازش انتخاب شده‌اند. در مرحله بعد، لایه‌های دیگری مانند 
    Max-Pooling 
    برای کاهش ابعاد و لایه‌های یادگیری بدون ناظر برای استخراج ویژگی‌های پیچیده‌تر به شبکه اضافه خواهند شد.

    شبکه عصبی ضربه‌ای طراحی شده در این پروژه با الهام از ساختارها و مکانیسم‌های معرفی شده در چارچوب 
    CoNeX 
    ساخته شده است. 
    CoNeX 
    یک چارچوب محاسباتی برای مدل‌سازی و شبیه‌سازی شبکه‌های عصبی ضربه‌ای با الهام از سیستم‌های عصبی بیولوژیکی است و ابزارهای مختلفی را برای پیاده‌سازی و ارزیابی این نوع شبکه‌ها فراهم می‌کند.
    
    در این شبکه عصبی ضربه‌ای، تصاویر ورودی ابتدا توسط فیلترهای DoG پردازش و کدگذاری می‌شوند. سپس، لایه‌های دیگری مانند 
    Max-Pooling 
    و لایه‌های یادگیری بدون ناظر به شبکه اضافه می‌شوند تا ویژگی‌های پیچیده‌تری از تصاویر استخراج شود. این شبکه عصبی ضربه‌ای سپس با استفاده از مجموعه‌ای از تصاویر طبیعی آموزش داده شده و نتایج حاصله تحلیل و بررسی می‌شود.
    
    هدف نهایی از این بخش، بررسی تأثیر پارامترهای مختلف فیلترها و لایه‌ها بر عملکرد شبکه و بهبود دقت در تشخیص و طبقه‌بندی تصاویر است. با انجام این مرحله، دانشجویان با مفاهیم و تکنیک‌های مختلف در طراحی و پیاده‌سازی شبکه‌های عصبی ضربه‌ای آشنا شده و توانایی‌های عملی خود را در این زمینه بهبود می‌بخشند.

    \section{معماری شبکه}
    معماری شبکه عصبی ضربه‌ای (Spiking Neural Network) که در این پروژه پیاده‌سازی شده است، شامل یک لایه ورودی، یک لایه خروجی و سیناپس‌های متصل‌کننده این دو لایه می‌باشد. این معماری با هدف پردازش و تحلیل تصاویر ورودی به صورت موثر و کارآمد طراحی شده است. در ادامه، به توضیح جزئیات هر یک از اجزای این معماری می‌پردازیم.

    \subsection*{لایه ورودی}
        لایه ورودی اولین بخش شبکه است که تصاویر را دریافت کرده و آنها را به ضربه‌های نورونی تبدیل می‌کند. فرآیند در این لایه شامل چند مرحله است:
        \begin{itemize}
            \item \textbf{تبدیل تصاویر به مقیاس خاکستری:} در ابتدا، تصاویر رنگی به تصاویر خاکستری تبدیل می‌شوند تا پردازش ساده‌تر و سریع‌تر انجام شود.
            \item \textbf{اعمال فیلتر 
            DoG:} 
            این فیلتر به منظور استخراج ویژگی‌های کلیدی از تصاویر به کار می‌رود. فیلتر 
            DoG 
            تفاوت بین دو تابع گوسی با مقیاس‌های مختلف را محاسبه می‌کند و به تشخیص لبه‌ها و جزئیات مهم کمک می‌کند.
            \item \textbf{نرمال‌سازی و تغییر اندازه:} تصاویر نرمال‌سازی شده و به ابعاد مناسب برای پردازش در شبکه تغییر اندازه داده می‌شوند.
            \item \textbf{مدل نورونی تجمیع و آتش نشتی:}  این مدل برای شبیه‌سازی رفتار نورون‌های بیولوژیکی استفاده می‌شود. نورون‌ها در این مدل با دریافت ورودی‌ها، بار الکتریکی را جمع‌آوری کرده و پس از رسیدن به یک آستانه مشخص، تخلیه می‌شوند و ضربه تولید می‌کنند.
            \item \textbf{کدگذاری ضربه‌های نورونی:} در نهایت، تصاویر به ضربه‌های نورونی تبدیل می‌شوند. این کدگذاری به شکل Time-to-First-Spike 
            انجام می‌شود که در آن شدت پیکسل‌ها به زمان تأخیر ضربه‌ها تبدیل می‌شود.
        \end{itemize}
    \subsection*{لایه خروجی} 
        لایه خروجی شامل گروهی از نورون‌ها است که مسئول پردازش و تحلیل نهایی ویژگی‌های استخراج شده از تصاویر هستند. ویژگی‌های اصلی این لایه عبارتند از:
        \begin{itemize}
            \item \textbf{مدل نورونی تجمیع و آتش نشتی:} 
            دقیقا همان مدلیست که در لایه اول استفاده شده است.
            \item \textbf{مکانیسم 
            KWTA (k-Winners-Take-All):}
            این مکانیسم برای محدود کردن تعداد نورون‌های فعال در هر لحظه استفاده می‌شود و به افزایش کارایی و دقت شبکه کمک می‌کند.
            \item \textbf{\lr{Spike Trace} و \lr{Homeostasis} :}  این ویژگی‌ها برای تنظیم فعالیت نورون‌ها و حفظ تعادل شبکه استفاده می‌شوند، به طوری که شبکه به طور پایدار عمل کند و از بیش‌فعالی یا کم‌فعالی نورون‌ها جلوگیری شود.
        \end{itemize}

    \subsection*{سیناپس ها}
        سیناپس‌ها اتصالاتی هستند که اطلاعات را بین لایه‌های ورودی و خروجی انتقال می‌دهند. در این شبکه، سیناپس‌ها از کانولوشن برای انتقال سیگنال‌ها و یادگیری استفاده می‌کنند. رفتار های کلیدی سیناپس‌ها عبارتند از:
        \begin{itemize}
            \item \textbf{نرمال سازی وزن ها\footnote{\lr{Weight Normalization:}}}  این فرآیند به تنظیم وزن‌های سیناپس‌ها کمک می‌کند تا سیگنال‌ها به طور متناسب و بهینه انتقال یابند.
            \item \textbf{\lr{Conv2dSTDP} :} این مکانیزم یادگیری بر پایه زمان‌بندی ضربه‌ها عمل می‌کند. اگر یک نورون پس از دیگری ضربه بزند، وزن سیناپسی بین آن‌ها تقویت یا تضعیف می‌شود. این مدل یادگیری را در پروژه های قبل به طور مفصل بررسی کردیم. در این شبکه، 
            STDP 
            به صورت کانولوشنی اعمال می‌شود که امکان یادگیری ویژگی‌های پیچیده را فراهم می‌کند.
            \item \textbf{مهار جانبی (\lr{Lateral Inhibition}): }
            این ویژگی به تنظیم فعالیت نورون‌ها در لایه خروجی کمک می‌کند، به طوری که فعالیت یک نورون می‌تواند فعالیت نورون‌های مجاور را مهار کند و از فعال شدن همزمان بیش از حد نورون‌ها جلوگیری کند.
        \end{itemize}

    \section{آموزش شبکه}
        در این پروژه از مجموعه داده‌های 
        \lr{Yale Faces} 
        برای آموزش و ارزیابی شبکه عصبی ضربه‌ای استفاده شده است. مجموعه داده‌های 
        \lr{Yale Faces} 
        یکی از مجموعه داده‌های شناخته شده و پرکاربرد در زمینه شناسایی و تشخیص چهره است. این مجموعه داده شامل تصاویر چهره افراد مختلف با حالات و شرایط نوری متفاوت می‌باشد. در شکل 
        \ref{fig:part2-sample-dataset}
        چند نمونه از این دیتاست آورده شده است.
        \paragraph*{مشخصات مجموعه داده \lr{Yale Faces}}
        \begin{itemize}
            \item \textbf{تعداد تصاویر:} مجموعه داده 
            \lr{Yale Faces} 
            شامل 165 تصویر از 
            15 
            فرد مختلف است. هر فرد در 
            11 
            حالت مختلف چهره عکاسی شده است که شامل حالت‌های مختلف نوری و حالات چهره (مانند لبخند زدن، چشم‌های بسته، و غیره) می‌شود.
            \item \textbf{ابعاد تصاویر:} تمامی تصاویر در این مجموعه داده به صورت سیاه و سفید با ابعاد
            ۱۰۰*۱۰۰
            انتخاب شده اند.
            \item \textbf{حالات چهره:} تمامی حالات چهره انتخاب شده، عادی و بدون حالت انتخاب شده‌اند.
        \end{itemize}


        \begin{figure}[!ht]
            \centering
            \includegraphics[width=0.8\textwidth]{plots/part2-sample-dataset.pdf} 
            \captionsetup{width=.7\linewidth}
            \caption{\textbf{چند نمونه تصویر از دیتاست اصلی} 
            }
            \label{fig:part2-sample-dataset}
        \end{figure}

        \subsection{پیش‌پردازش داده‌ها}
            برای آماده‌سازی داده‌ها برای ورود به شبکه عصبی ضربه‌ای، مجموعه داده 
            \lr{Yale Faces} 
            تحت چند مرحله پیش‌پردازش قرار گرفته است:
            \begin{itemize}
                \item \textbf{تبدیل به مقیاس خاکستری:} تصاویر رنگی موجود در مجموعه داده به تصاویر خاکستری تبدیل شده‌اند. این کار به منظور کاهش پیچیدگی و حجم محاسباتی پردازش تصاویر انجام شده است.
                \item \textbf{اعمال فیلتر 
                DoG :} به منظور استخراج ویژگی‌های کلیدی از تصاویر، فیلتر DoG 
                بر روی تصاویر اعمال شده است. این فیلتر به شناسایی لبه‌ها و جزئیات مهم در تصاویر کمک می‌کند.
                \item \textbf{نرمال‌سازی و تغییر اندازه:}
                 تصاویر نرمال‌سازی شده و به ابعاد مناسبی برای پردازش در شبکه 
                 (مانند 128x128 پیکسل) 
                 تغییر اندازه داده شده‌اند. این کار باعث می‌شود که تمامی تصاویر ورودی دارای ابعاد یکنواختی باشند و پردازش بهینه‌تر انجام شود.
                 \item \textbf{کدگذاری ضربه‌های نورونی:} تصاویر نرمال‌سازی شده و تغییر اندازه داده شده به ضربه‌های نورونی تبدیل شده‌اند. این کدگذاری به شکل Time-to-First-Spike 
                 انجام شده است که در آن شدت پیکسل‌ها به زمان تأخیر ضربه‌ها تبدیل می‌شود.
            \end{itemize}

        این مجموعه داده با توجه به تنوع حالات چهره و شرایط نوری مختلف، یک چالش مناسب برای ارزیابی و بهبود عملکرد شبکه عصبی ضربه‌ای فراهم می‌کند. استفاده از این داده‌ها به ما امکان می‌دهد تا کارایی و دقت شبکه را در شرایط مختلف بررسی کنیم و به بهبود معماری و روش‌های یادگیری شبکه بپردازیم.
        
        \subsection{آموزش شبکه}
            در این بخش از گزارش، به تحلیل و بررسی عملکرد شبکه عصبی ضربه‌ای 
            (SNN) مان
            که پیاده‌سازی شده است، می‌پردازیم. هدف از انجام این آزمایش‌ها، بررسی دقت و کارایی شبکه در پردازش و تشخیص ویژگی های تکراری تصاویر مجموعه داده است. همچنین، تحلیل عمیق‌تری از نحوه استخراج ویژگی‌ها توسط لایه کانولوشن و تأثیر پارامترهای مختلف بر عملکرد شبکه انجام می‌دهیم.
            
            ابتدا به تحلیل و بررسی نتایج حاصل از اولین آزمایش انجام شده توسط شبکه‌مان
            می‌پردازیم. هدف این آزمایش بررسی عملکرد شبکه در استخراج ویژگی‌های مهم از تصاویر ورودی با استفاده از لایه کانولوشن و تحلیل صفحه‌های ویژگی 
            (Feature Maps) 
            به دست آمده است. پارامترهای تنظیم شده برای این آزمایش شامل تعداد فیلترها، اندازه فیلترها، نرخ فعالیت و پارامترهای یادگیری است که به صورت زیر تعریف شده‌اند:
            \begin{multicols}{3}
                پارامتر های لایه ورودی:
                \begin{itemize}
                \item تعداد مراحل شبیه‌سازی: ۹۹۰
                \item پنجره زمانی ورودی: ۱۰
                \item طول لایه اول: ۱۰۰
                \item عرض لایه اول: ۱۰۰
                \item $\tau_{trace}$ لایه اول: ۴
                \item تعداد کانال های ورودی: ۱
                \end{itemize}
                
                \columnbreak
                
                پارامتر های لایه دوم:
                \begin{itemize}
                \item طول کرنل: ۱۱
                \item عرض کرنل: ۱۱
                \item تعداد صفحه های ویژگی: ۹
                \item طول لایه خروجی:  تفاضل طول لایه ورودی و کرنل به علاوه ۱
                \item عرض لایه خروجی:  تفاضل عرض لایه ورودی و کرنل به علاوه ۱
                \item آستانه ضربه زدن نورون ها: ۱۵
                \item $\tau$ نورون ها: ۳
                \item $v_{rest}$ نورون ها: ۵
                \item مقاومت نورون ها: ۱۰
                \item $tau_{trace}$ نورون ها: ۳
                \end{itemize}
                \columnbreak

                پارامتر های ساز و کار ها:
                \begin{itemize}
                \item k در kwta: ۱
                \item نرخ فعالیت: ۰.۲
                \item اندازه پنجره فعالیت: ۱۰
                \item نرخ بروزرسانی فعالیت: ۱
                \item ضریب وزن ها: ۳۰۰
                \item مقدار $A_{+}$ : ۲
                \item مقدار $A_{-}$ : ۱
                \item مقدار ضریب مهار جانبی: ۱۰۰
                \end{itemize}
                \end{multicols}

                مطابق شکل 
                \ref{fig:part2-exp1-extracted-features}
                صفحه های ویژگی به دست آمده از لایه کانولوشن، نشان‌دهنده الگوهای مختلفی است که فیلترهای کانولوشنی استخراج کرده‌اند. در این آزمایش، از
                9
                فیلتر کانولوشن با ابعاد 
                ۹*۹
                استفاده شده است. هر یک از صفحه‌های ویژگی به صورت یک ماتریس نمایش داده شده است که نشان‌دهنده وزن یادگرفته شده سیناپس بین نورون‌ها در پاسخ به ویژگی‌های مختلف تصویر ورودی است.

                در تصاویر صفحه های ویژگی ارائه شده، می‌توان مشاهده کرد که هر فیلتر به ویژگی‌های مختلفی از تصویر حساس است. برخی از فیلترها به لبه‌های عمودی، برخی به لبه‌های افقی و برخی به نواحی با شدت نور مختلف حساسیت نشان داده‌اند. این نشان می‌دهد که فیلترهای کانولوشن توانسته‌اند ویژگی‌های مهمی را از تصاویر ورودی استخراج کنند.

                \begin{figure}[!ht]
                    \centering
                    \includegraphics[width=0.8\textwidth]{plots/part2-exp1-extracted-features.pdf} 
                    \captionsetup{width=.9\linewidth}
                    \caption{\textbf{آزمایش اول: ویژگی های استخراج شده.} در آزمایش اول با یک سری پارامتر اولیه شروع می‌کنیم و رفته رفته پارامترها را بهبود می‌دهیم. مطابق شکل  هر تصویر نشان‌دهنده الگوهایی است که یک فیلتر خاص از تصویر ورودی استخراج کرده است. این صفحه‌ها نشان می‌دهند که فیلترها به لبه‌ها و نواحی با شدت نور مختلف حساسیت دارند و ویژگی‌های متنوعی از تصاویر ورودی را شناسایی می‌کنند. هر چند که بعضی ویژگی ها به خوبی استخراج شده اند، ولی هنوز شاهد ویژگی هایی هستیم که می‌توانند بهتر شوند.
                    }
                    \label{fig:part2-exp1-extracted-features}
                \end{figure}

                حال ویژگی های استخراج شده را، روی یک تصویر ورودی هم‌گشت می‌کنیم تا نتیجه استخراج ویژگی ها را مشاهده کنیم. به عنوان مثال، در شکل 
                \ref{fig:part2-exp1-output-last-iteration-single}
                مشاهده می‌کنیم که ویژگی شماره ۶ توانسته است لبه ها را به خوبی تشخیص دهد.

                \begin{figure}[!ht]
                    \centering
                    \includegraphics[width=0.8\textwidth]{plots/part2-exp1-output-last-iteration-single.pdf} 
                    \captionsetup{width=.9\linewidth}
                    \caption{\textbf{ هم‌گشت ویژگی های استخراج شده روی یک نمونه تصویر ورودی.}  این تصویر حاصل عملیات کانولوشن یکی از فیلترهای شبکه بر روی تصویر ورودی در آخرین تکرار آموزش است. نواحی سفید نشان‌دهنده نورون‌های فعال شده هستند که نشان می‌دهد فیلتر کانولوشنی توانسته ویژگی‌های خاصی از تصویر ورودی را شناسایی و استخراج کند. این خروجی نشان‌دهنده کارایی فیلترهای کانولوشنی در شناسایی و پردازش الگوهای موجود در تصویر است.
                    }
                    \label{fig:part2-exp1-output-last-iteration-single}
                \end{figure}

                برای بررسی دقیق‌تر و بهبود بیشتر عملکرد شبکه، به آزمایش دوم با پارامترهای جدید می‌پردازیم. در این آزمایش، پارامترهایی نظیر نرخ فعالیت، و تنظیمات کرنل‌ها تغییر یافته‌اند تا تاثیر این تغییرات بر عملکرد کلی شبکه مورد ارزیابی قرار گیرد. 
            
                همانطور که در شکل 
                \ref{fig:part2-exp2-extracted-features}
                مشاهده می‌کنید، با افزایش 
                $\tau_s$، 
                و همچنین پارامتر های 
                $A_{+}$ و $A_{-}$ 
                شاهد بهبود هایی در صفحه های ویژگی پیدا شده هستیم. هرچند هنوز نیز می‌توان انتظار بهبود بیشتری نیز داشت. به عنوان مثال، چهار ویژگی از صفحات ویژگی مشابه یکدیگر هستند و یک چیز را یادگرفته‌اند. 

                \begin{figure}[!ht]
                    \centering
                    \includegraphics[width=0.8\textwidth]{plots/part2-exp2-extracted-features.pdf} 
                    \captionsetup{width=.9\linewidth}
                    \caption{\textbf{ صفحه های ویژگی به دست آمده از فیلترهای کانولوشن در لایه دوم با پارامترهای بهبود یافته: تنظیم پارامتر $\tau_s$. } در آزمایش دوم، مقدار 
                    $tau_s$ را بیشتر کرده و مطابق شکل ملاحظه می‌کنیم که ویژگی های بهتری استخراج شده است.
                    افزایش مقدار 
                    $\tau_s$ 
                    به 10، زمان پایداری سیگنال‌ها را افزایش می‌دهد که منجر به استخراج بهتر ویژگی‌های زمانی می‌شود.
                    }
                    \label{fig:part2-exp2-extracted-features}
                \end{figure}

                مطابق شکل
                \ref{fig:part2-exp2-output-last-duration} 
                می‌توان مشاهده کرد که نورون‌های مختلف در عمق‌های مختلف شبکه به ویژگی‌های خاصی از تصویر ورودی واکنش نشان داده‌اند. نواحی سفید نشان‌دهنده نورون‌های فعال شده هستند که نشان می‌دهد فیلتر کانولوشنی توانسته ویژگی‌های خاصی از تصویر ورودی را شناسایی و استخراج کند. فیلترهای کانولوشنی توانسته‌اند ویژگی‌های متنوعی از تصاویر ورودی را استخراج کنند که نشان‌دهنده قدرت شبکه در تشخیص الگوهای مختلف است. برخی از صفحه‌های ویژگی و خروجی‌های نهایی وضوح کمتری دارند و نشان‌دهنده این است که ممکن است برخی از فیلترها نیاز به تنظیمات بیشتری داشته باشند.

                \begin{figure}[!ht]
                    \centering
                    \includegraphics[width=0.8\textwidth]{plots/part2-exp2-output-last-duration.pdf} 
                    \captionsetup{width=.9\linewidth}
                    \caption{\textbf{ خروجی شبکه در آخرین پنجره زمانی برای هر یک از   فیلترهای کانولوشن: تنظیم پارامتر $\tau_s$. } مطابق شکل ملاحظه می‌کنیم که شبکه توانسته است تعداد خوبی از ویژگی های تصاویر را یاد بگیرد به طوری که بعضی از ویژگی های چهره مانند فرم کلی در خروجی ها مشهود است. نواحی سفید نشان‌دهنده نورون‌های فعال شده هستند که نشان می‌دهند فیلترهای کانولوشنی توانسته‌اند ویژگی‌های خاصی از تصویر ورودی را شناسایی و استخراج کنند. این خروجی‌ها نشان‌دهنده کارایی فیلترهای کانولوشنی در شناسایی و پردازش الگوهای موجود در تصویر هستند. با افزایش $\tau_s$، شبکه توانسته است الگوهای بهتری و متنوع‌تری را از تصاویر استخراج کند که بهبود قابل توجهی در دقت شناسایی ویژگی‌های کلی را نشان می‌دهد.
                    }
                    \label{fig:part2-exp2-output-last-duration}
                \end{figure}

                در آخر، به بررسی پارامتر های 
                $A_{plus}$ و $A_{minus}$ 
                می‌پردازیم. این دو پارامتر از مهم ترین پارامتر های شبکه هستند چرا که مستقیما روی یادگیری شبکه تاثیر دارند. مطابق  شکل 
                \ref{fig:part2-exp3-extracted-features} 
                مشاهده می‌کنیم که تنظیم درست این پارامتر ها می‌تواند ویژگی های استخراج شده را به شدت بهبود دهد به طوری که تنوع ویژگی های پیدا شده افزایش یافته است.

                \begin{figure}[!ht]
                    \centering
                    \includegraphics[width=0.8\textwidth]{plots/part2-exp3-extracted-features.pdf} 
                    \captionsetup{width=.9\linewidth}
                    \caption{\textbf{  صفحه های ویژگی به دست آمده از فیلترهای کانولوشن در لایه دوم با پارامترهای بهبود یافته: تنظیم پارامتر های یادگیری.}  هر تصویر نشان‌دهنده الگوهایی است که یک فیلتر خاص از تصویر ورودی استخراج کرده است. مشاهده می‌کنیم که تنظیم درست پارمتر های یادگیری
                    ($A_{plus}$ و $A_{minus}$) 
                    توانسته است به خوبی ویژگی های مختلف را استخراج کند. 
                    این صفحه ها نشان می‌دهند که فیلترها به لبه‌ها و نواحی با شدت نور مختلف حساسیت دارند و ویژگی‌های متنوع‌تری از تصاویر ورودی را شناسایی می‌کنند. پارامترهای استفاده شده در این آزمایش در قسمت بالا سمت راست تصویر آورده شده‌اند.
                    }
                    \label{fig:part2-exp3-extracted-features}
                \end{figure}

                در شکل 
                \ref{fig:part2-exp3-output-last-duration}
                می‌توان مشاهده کرد که نورون‌های مختلف در عمق‌های مختلف شبکه به ویژگی‌های خاصی از تصویر ورودی واکنش نشان داده‌اند. نواحی سفید نشان‌دهنده نورون‌های فعال شده هستند که نشان می‌دهد فیلتر کانولوشنی توانسته ویژگی‌های خاصی از تصویر ورودی را شناسایی و استخراج کند. در یکی از تصاویر، صورت به خوبی تشخیص داده شده است که نشان‌دهنده بهبود قابل توجه دقت و کارایی شبکه است.

                \begin{figure}[!ht]
                    \centering
                    \includegraphics[width=0.8\textwidth]{plots/part2-exp3-output-last-duration.pdf} 
                    \captionsetup{width=.9\linewidth}
                    \caption{\textbf{ خروجی شبکه در آخرین پنجره زمانی برای هر یک از فیلترهای کانولوشن: تنظیم پارامتر های یادگیری. } مطابق شکل ملاحظه می‌کنیم که شبکه توانسته است تعداد بیشتری از ویژگی های تصاویر را یاد بگیرد به طوری که بعضی از ویژگی های چهره مانند فرم کلی یا خطوط عمودی و افقی صورت و همچنین جای چشم ها در خروجی ها مشهود است. نواحی سفید نشان‌دهنده نورون‌های فعال شده هستند که نشان می‌دهد فیلتر کانولوشنی توانسته ویژگی‌های خاصی از تصویر ورودی را شناسایی و استخراج کند. در یکی از تصاویر، صورت به خوبی تشخیص داده شده است که نشان‌دهنده بهبود قابل توجه دقت و کارایی شبکه است.
                    }
                    \label{fig:part2-exp3-output-last-duration}
                \end{figure}

                در شکل 
                \ref{fig:part2-exp3-conv-feature-single}
                نیز نتیجه هم‌گشت یکی از فیلتر های آزمایش سوم بر روی یک نمونه تصویر ورودی آمده است. مطابق شکل ملاحظه می‌کنیم که نسبت به آزمایش قبل نتیجه بهتر است.

                \begin{figure}[!ht]
                    \centering
                    \includegraphics[width=0.8\textwidth]{plots/part2-exp3-conv-feature-single.pdf} 
                    \captionsetup{width=.9\linewidth}
                    \caption{\textbf{ ویژگی های استخراج شده روی یک نمونه تصویر: تنظیم پارامتر های یادگیری. } مطابق شکل ملاحظه می‌کنیم که در این آزمایش با تنظیم پارامتر های گفته شده، ویژگی های استخراج شده نیز بهبود یافتند و تصویر هم‌گشت شده از یک نمونه تصویر دارای دقت بیشتری است.
                    }
                    \label{fig:part2-exp3-conv-feature-single}
                \end{figure}

                حال به بررسی تأثیر کاهش اندازه کرنل‌های کانولوشن بر عملکرد شبکه
                می‌پردازیم. اندازه کرنل‌ها نقش مهمی در فرآیند استخراج ویژگی‌های مختلف از تصاویر ورودی دارند. کاهش اندازه کرنل ممکن است به شبکه کمک کند تا جزئیات دقیق‌تری از تصاویر را استخراج کند و در عین حال پیچیدگی محاسباتی را کاهش دهد. هدف از این آزمایش، بررسی تأثیر تغییرات در اندازه کرنل بر وضوح و تنوع صفحه های ویژگی 
                و کارایی کلی شبکه در شناسایی و طبقه‌بندی الگوهای موجود در تصاویر ورودی است. با انجام این آزمایش، به دنبال یافتن اندازه بهینه کرنل برای بهبود دقت و کارایی شبکه هستیم.

                تصاویر صفحه‌های ویژگی به دست آمده از فیلترهای کانولوشن در لایه دوم شبکه، نشان‌دهنده الگوهای مختلفی است که فیلترها از تصویر ورودی استخراج کرده‌اند. در این آزمایش از
                9
                فیلتر کانولوشن با ابعاد 
                5*5
                استفاده شده است. هر یک از صفحه‌های ویژگی به صورت ماتریسی نمایش داده شده‌اند که شدت فعالیت نورون‌ها را در پاسخ به ویژگی‌های مختلف تصویر ورودی نشان می‌دهد. مطابق شکل 
                \ref{fig:part2-exp4-extracted-features-decrease-size}
                صفحه های ویژگی به دست آمده از فیلترهای کانولوشن در لایه دوم شبکه با اندازه کرنل کاهش یافته به 
                ۵*۵
                آمده است. هر تصویر نشان‌دهنده الگوهایی است که یک فیلتر خاص از تصویر ورودی استخراج کرده است. این نقشه‌ها نشان می‌دهند که فیلترها به لبه‌ها و نواحی با شدت نور مختلف حساسیت دارند و ویژگی‌های متنوع‌تری از تصاویر ورودی را شناسایی می‌کنند.

                \begin{figure}[!ht]
                    \centering
                    \includegraphics[width=0.8\textwidth]{plots/part2-exp4-extracted-features-decrease-size.pdf} 
                    \captionsetup{width=.9\linewidth}
                    \caption{\textbf{ صفحه های ویژگی به دست آمده از فیلترهای کانولوشن در لایه دوم با پارامترهای بهبود یافته: کاهش ابعاد صفحات ویژگی}  در تصاویر صفحه های ویژگی، می‌توان مشاهده کرد که هر فیلتر به ویژگی‌های مختلفی از تصویر حساس است. برخی از فیلترها به لبه‌های عمودی، برخی به لبه‌های افقی و برخی به نواحی با شدت نور مختلف حساسیت نشان داده‌اند. این نشان می‌دهد که فیلترهای کانولوشن با اندازه کوچک‌تر نیز توانسته‌اند ویژگی‌های مهمی را از تصاویر ورودی استخراج کنند. با این حال، وضوح برخی از صفحه های ویژگی نسبت به آزمایش‌های قبلی کاهش یافته است که ممکن است به دلیل اندازه کوچک‌تر کرنل باشد.
                    }
                    \label{fig:part2-exp4-extracted-features-decrease-size}
                \end{figure}

                مطابق شکل 
                \ref{fig:part2-exp4-output-last-duration}
                خروجی شبکه در آخرین پنجره زمانی برای هر یک از عمق‌های مختلف فیلترهای کانولوشن با اندازه کرنل کاهش یافته به 
                ۵*۵ 
                آمده است.
                نواحی سفید نشان‌دهنده نورون‌های فعال شده هستند که نشان می‌دهند فیلترهای کانولوشنی توانسته‌اند ویژگی‌های خاصی از تصویر ورودی را شناسایی و استخراج کنند.

                \begin{figure}[!ht]
                    \centering
                    \includegraphics[width=0.8\textwidth]{plots/part2-exp4-output-last-duration.pdf} 
                    \captionsetup{width=.9\linewidth}
                    \caption{\textbf{ خروجی شبکه در آخرین پنجره زمانی برای هر یک از فیلترهای کانولوشن: کاهش ابعاد صفحات ویژگی. } در این تصاویر می‌توان مشاهده کرد که نورون‌های مختلف در عمق‌های مختلف شبکه به ویژگی‌های خاصی از تصویر ورودی واکنش نشان داده‌اند.(
                        مانند لبه های عمودی، افقی
                    ) نواحی سفید نشان‌دهنده نورون‌های فعال شده هستند که نشان می‌دهد فیلتر کانولوشنی توانسته ویژگی‌های خاصی از تصویر ورودی را شناسایی و استخراج کند. با این حال، وضوح و تعداد نورون‌های فعال شده در برخی از عمق‌ها نسبت به آزمایش‌های قبلی کمتر است.
                    }
                    \label{fig:part2-exp4-output-last-duration}
                \end{figure}

                در شکل 
                \ref{fig:part2-exp4-conv-feature-single}
                نیز عملیات هم‌گشت روی یک نمونه تصویر ورودی انجام شده است. مطابق شکل ملاحظه می‌کنیم که کرنل کوچک تر و با پارامتر های بهبود یافته به خوبی توانسته است ویژگی هایی را از ورودی استخراج کند.

                \begin{figure}[!ht]
                    \centering
                    \includegraphics[width=0.8\textwidth]{plots/part2-exp4-conv-feature-single.pdf} 
                    \captionsetup{width=.9\linewidth}
                    \caption{\textbf{ ویژگی های استخراج شده روی یک نمونه تصویر: کاهش ابعاد صفحات ویژگی. } مطابق شکل ملاحظه می‌کنیم که در این آزمایش با تنظیم پارامتر های گفته شده، ویژگی های استخراج شده نیز بهبود یافتند و تصویر هم‌گشت شده از یک نمونه تصویر دارای دقت خوبی است.
                    }
                    \label{fig:part2-exp4-conv-feature-single}
                \end{figure}

                حال به بررسی تأثیر افزایش اندازه کرنل‌های کانولوشن بر عملکرد شبکه
                می‌پردازیم. افزایش اندازه کرنل‌ها ممکن است به شبکه کمک کند تا ویژگی‌های بیشتری را از نواحی بزرگ‌تری از تصاویر استخراج کند، که می‌تواند منجر به بهبود دقت در شناسایی الگوهای پیچیده‌تر شود. هدف از این آزمایش، بررسی تغییرات در وضوح و تنوع صفحات ویژگی
                و کارایی کلی شبکه در شناسایی و طبقه‌بندی الگوهای موجود در تصاویر ورودی با افزایش اندازه کرنل‌ها است. با انجام این آزمایش، به دنبال یافتن اندازه بهینه کرنل برای بهبود دقت و کارایی شبکه هستیم.

                مطابق شکل 
                \ref{fig:part2-exp5-extracted-features-increase-size}
                مشاهده می‌کنیم که با افزایش اندازه صفحهات ویژگی، ویژگی های استخراج شده از تصاویر ورودی نیز نسبتا بزرگتر شده اند. هر چند برخی وزن ها به طور کامل موفق به یادگیری نشده اند، ولی نتیجه کلی مطلوب است.

                در شکل 
                \ref{fig:part2-exp5-output-last-duration}
                نیز خروجی این تصاویر در لایه آخر که حاصل کانولوشن لایه اول در صفحات ویژگی هاست آمده است.

                \begin{figure}[!ht]
                    \centering
                    \includegraphics[width=0.8\textwidth]{plots/part2-exp5-extracted-features-increase-size.pdf} 
                    \captionsetup{width=\linewidth}
                    \caption{\textbf{ صفحه های ویژگی به دست آمده از فیلترهای کانولوشن در لایه دوم با پارامترهای بهبود یافته: افزایش ابعاد صفحات ویژگی.}  در تصاویر صفحه های ویژگی، می‌توان مشاهده کرد که هر فیلتر ویژگی‌های مختلف بزرگتری از تصویر را یادگرفته است. افزایش اندازه کرنل منجر به شناسایی الگوهای بزرگ‌تر و پیچیده‌تر شده است. بعضی از صفحه های ویژگی وضوح بالاتری دارند و الگوهای بیشتری را نشان می‌دهند که این نشان‌دهنده توانایی بالای شبکه در شناسایی جزئیات پیچیده‌تر تصاویر است. هر چند بعضی از صفحات نیز موفق به یادگیری کامل الگو ها نشده اند. نکته مهمی که هنگام افزایش اندازه صفحات ویژگی باید توجه داشت، این موضوع است که پارمتر ساز و کار مهار جانبی نیز باید تغییر کند. 
                    این فرایند برای حفظ تعادل فعالیت نورون‌ها و جلوگیری از فعال شدن بیش از حد آنها مهم است. با افزایش اندازه کرنل، تعداد نورون‌های فعال شده افزایش می‌یابد، بنابراین برای جلوگیری از فعالیت بیش از حد و حفظ تعادل، پارامتر مهار جانبی نیز باید تغییر کند.
                    }
                    \label{fig:part2-exp5-extracted-features-increase-size}
                \end{figure}
                
                \begin{figure}[!ht]
                    \centering
                    \includegraphics[width=0.8\textwidth]{plots/part2-exp5-output-last-duration.pdf} 
                    \captionsetup{width=.9\linewidth}
                    \caption{\textbf{ خروجی شبکه در آخرین پنجره زمانی برای هر یک از فیلترهای کانولوشن: افزایش ابعاد صفحات ویژگی. } از آنجا که ابعاد کرنل بزرگتر شده است، در این تصاویر می‌توان مشاهده کرد که نورون‌های مختلف در عمق‌های مختلف شبکه به ویژگی‌های کلی تری از تصویر ورودی واکنش نشان داده‌اند، مانند فرم کلی صورت، محل قرار گیری چشم ها، موی سر یا بینی و اجزای دیگر صورت. 
                    }
                    \label{fig:part2-exp5-output-last-duration}
                \end{figure}
    
                \clearpage
    
    \section*{نتیجه گیری}
        در این پروژه، ما به بررسی و شبیه‌سازی پردازش اولیه تصاویر در سیستم بینایی انسان پرداختیم. با استفاده از فیلترهای تفاضل گاوسی 
        (DoG) 
        و گبور، موفق به شبیه‌سازی مکانیسم‌های پردازش اولیه در شبکیه و قشر بینایی اولیه
        شدیم. این فیلترها توانستند ویژگی‌های بصری مهمی مانند لبه‌ها و کنتراست‌ها را برجسته کرده و به شناسایی و تفسیر بهتر این ویژگی‌ها کمک کنند.

        استفاده از فیلترهای 
        DoG 
        و گبور نشان داد که چگونه می‌توان از مدل‌های محاسباتی برای تقلید از عملکرد بیولوژیکی سیستم بینایی استفاده کرد. نتایج حاصل از این شبیه‌سازی‌ها نشان داد که پیش‌پردازش تصاویر با این فیلترها می‌تواند به بهبود فرآیندهای کدگذاری عصبی و پردازش اطلاعات بصری منجر شود.
        
        همچنین در این پروژه به اهمیت نحوه کدگذاری عصبی ضربه‌ای 
        در پردازش اطلاعات بصری اشاره کردیم و نشان دادیم که چگونه این روش می‌تواند با استفاده از فیلترهای مناسب، کارایی و دقت پردازش‌های نورونی را افزایش دهد.
        
        در مجموع، این پروژه به درک بهتر از مکانیسم‌های پردازش اولیه در سیستم بینایی کمک کرد و نشان داد که چگونه می‌توان از مدل‌های محاسباتی برای مطالعه و تحلیل فرآیندهای پیچیده بیولوژیکی استفاده کرد.